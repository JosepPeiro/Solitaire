{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb264ad",
   "metadata": {},
   "source": [
    "# Apuntes Aprendizaje Reforzado\n",
    "\n",
    "Fuente: https://www.youtube.com/watch?v=Mut_u40Sqz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "764a62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     ------------------------------------ 721.7/721.7 kB 506.0 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jpeir\\anaconda3\\lib\\site-packages (from gym) (1.22.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jpeir\\anaconda3\\lib\\site-packages (from gym) (2.2.1)\n",
      "Collecting gym-notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\jpeir\\anaconda3\\lib\\site-packages (from gym) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jpeir\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.11.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827632 sha256=511e7ee1419bda8ebe23b4917cb5d03d102a4d39851eb2dc5106351674853da6\n",
      "  Stored in directory: c:\\users\\jpeir\\appdata\\local\\pip\\cache\\wheels\\17\\79\\65\\7afedc162d858b02708a3b8f7a6dd5b1000dcd5b0f894f7cc1\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable-baselines3[extra]\n",
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fa4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "#Esto es el el algoritmo de aprendizaje que vamos a utilizar, aunque hay muchos diferentes\n",
    "# y puede que este no sea el que nosotros necesitemos\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# DummyVecEnv nos sirve para vectorizar nuestros entornos y es maravilloso porque nos\n",
    "# posibilita hacer muchas simulaciones en un vector, lo que acelera el proceso de manera extrema\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# Esta libraria es para evaluar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc35425",
   "metadata": {},
   "source": [
    "## Cargar Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846c6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpeir\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "environment_name = \"CartPole-v0\"\n",
    "env = gym.make(environment_name)\n",
    "# Vamos a trabajar con un problema de RL que consiste en mantener una barra vertical sin que caiga\n",
    "# La barra se encuentra sobre una plataforma móvil\n",
    "# El problema con el que trabajamos y cómo este se describe es lo que llamamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1b6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 Score:9.0\n",
      "Episode:1 Score:13.0\n",
      "Episode:2 Score:22.0\n",
      "Episode:3 Score:20.0\n",
      "Episode:4 Score:14.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for ep in range(episodes):\n",
    "    state = env.reset()\n",
    "    # Reinicia el entorno\n",
    "    done = False\n",
    "    # Estado del entorno\n",
    "    score = 0\n",
    "    # Recompensa/Puntuación\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        # Muestra una interfaz del problema\n",
    "        action = env.action_space.sample()\n",
    "        # Realiza una acción aleatoria\n",
    "        # En este problema, como tal y como se define en el entorno, solo se pueden hacer 2 posibles opciones, izquierda o derecha\n",
    "        # Así que action_space es el espacio de posibles acciones, que como además son acciones discretas el objeto se guarda como Discrete(2)\n",
    "        # Luego, cuando hacemos sample tomamos una de las 2 posibles acciones aleatoriamente\n",
    "        n_state, reward, done, trunc, info = env.step(action)\n",
    "        # Ejecutamos la accion elegida con step\n",
    "        # Devuelve el estado al que pasamos (la definición del estado)\n",
    "        # La recompensa que adquiere en ese paso\n",
    "        # Si la mision se ha completado\n",
    "        # Si la mision ha podido completarse en menos del maximo de pasos posibles\n",
    "        # Informacion adicional\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\".format(ep, score))\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1cfb35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0193603 ,  0.21330012, -0.02149993, -0.25753242], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " env.reset()\n",
    "env.action_space.sample()\n",
    "env.step(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
